{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMPxSaGyhdslR20IrZ7Yfiq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajeevku1/AIAgentSamples/blob/main/ChatusingGradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a8nOd7dyNOVS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import json\n",
        "import gradio as gr\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "openai = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "MMwM-5jNO4_G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def message_gpt(prompt, modName):\n",
        "    \"\"\"Non-streaming function for simple message queries\"\"\"\n",
        "    if not openai:\n",
        "        return \"Error: OpenAI API key not set\"\n",
        "\n",
        "    system_message = \"You are a helpful assistant\"\n",
        "    print(\"Selected model : \" + modName)\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "aGA47iNQOsg0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatWithAIusingGrido():\n",
        "    # Let's use Markdown\n",
        "    # Are you wondering why it makes any difference to set system_message when it's not referred to in the code below it?\n",
        "    # I'm taking advantage of system_message being a global variable, used back in the message_gpt function (go take a look)\n",
        "    # Not a great software engineering practice, but quite common during Jupyter Lab R&D!\n",
        "\n",
        "    system_message = \"You are a helpful assistant that responds in markdown without code blocks\"\n",
        "    message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message for GPT-4.1-mini\", lines=7)\n",
        "    model_Name  = gr.Dropdown([\"GPT\"],label=\"Select model\", value=\"GPT\")\n",
        "    message_output = gr.Markdown(label=\"Response:\")\n",
        "\n",
        "    view = gr.Interface(\n",
        "        fn=message_gpt,\n",
        "        title=\"GPT\",\n",
        "        inputs=[message_input,model_Name],\n",
        "        outputs=[message_output],\n",
        "        flagging_mode=\"never\"\n",
        "        )\n",
        "    view.launch(inbrowser=True,auth=(\"Rajeev\", \"Welcome1\"))"
      ],
      "metadata": {
        "id": "yukO5tNXOFz6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatWithAIusingGrido()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "pFcsifbIPUZE",
        "outputId": "e2ce5bbf-3e35-483f-e8a6-00582770d889"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8e2f7d37f227796511.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8e2f7d37f227796511.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47b305eb"
      },
      "source": [
        "You can install Python libraries using `!pip install <library_name>`. For example, to install the `numpy` library, you would run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6559d42"
      },
      "source": [
        "!pip install numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d406726"
      },
      "source": [
        "After installation, you can import and use the library in your code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "032f0f5c"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print(np.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}