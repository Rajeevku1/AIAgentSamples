{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajeevku1/AIAgentSamples/blob/main/MeetingMinutesAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "M-mTmXz9USNe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FW8nl3XRFrz0"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI\n",
        "from google.colab import drive\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "openai = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "q3D1_T0uG_Qh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1: Transcribe Audio"
      ],
      "metadata": {
        "id": "2GLpveo8cgzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 1: Use Open Source for Transcription - Hugging Face Pipelines"
      ],
      "metadata": {
        "id": "4q8VHUWKcAAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=\"openai/whisper-medium.en\",\n",
        "    dtype=torch.float16,\n",
        "    device='cuda',\n",
        "    return_timestamps=True\n",
        ")\n",
        "\n",
        "result = pipe(audio_filename)\n",
        "transcription = result[\"text\"]\n",
        "print(transcription)"
      ],
      "metadata": {
        "id": "2JJmv8sFb_OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 2: Use OpenAI for Transcription"
      ],
      "metadata": {
        "id": "0ogUN9PIcKTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sign in to OpenAI using Secrets in Colab\n",
        "\n",
        "AUDIO_MODEL = \"gpt-4o-mini-transcribe\"\n",
        "audio_filename = \"/tmp/audio.m4a\"\n",
        "# Open the file\n",
        "audio_file = open(audio_filename, \"rb\")\n",
        "transcription = openai.audio.transcriptions.create(model=AUDIO_MODEL, file=audio_file, response_format=\"text\")\n",
        "print(transcription)"
      ],
      "metadata": {
        "id": "qP6OB2OeGC2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38e386eb-15d2-44cd-e397-95bdc9678ee1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I wanted to report a problem regarding my card which has been lost. I want to make sure you can lock my card so that there is no fraud transaction happen.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(transcription))\n",
        "print(\"\\n\\n\")\n",
        "display(Markdown(transcription))"
      ],
      "metadata": {
        "id": "kh4Q9Yg-kLk4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "bb06014b-192f-4b25-d1c5-c3ae232a581c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I wanted to report a problem regarding my card which has been lost. I want to make sure you can lock my card so that there is no fraud transaction happen.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I wanted to report a problem regarding my card which has been lost. I want to make sure you can lock my card so that there is no fraud transaction happen.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2: Analyze & Report"
      ],
      "metadata": {
        "id": "8wt22rJFcYFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"\n",
        "You produce minutes of meetings from transcripts, with summary, key discussion points,\n",
        "takeaways and action items with owners, in markdown format without code blocks.\n",
        "\"\"\"\n",
        "\n",
        "user_prompt = f\"\"\"\n",
        "Below is an extract transcript of a RCLI Project demo meeting.\n",
        "Please write minutes in markdown without code blocks, including:\n",
        "- a summary with attendees, location and date\n",
        "- discussion points\n",
        "- takeaways\n",
        "- action items with owners\n",
        "\n",
        "Transcription:\n",
        "{transcription}\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"content\": user_prompt}\n",
        "  ]\n"
      ],
      "metadata": {
        "id": "piEMmcSfMH-O"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_response = openai.chat.completions.create(model=\"gpt-4o-mini\",messages=messages, temperature=0.7)\n",
        "meeting_summary = openai_response.choices[0].message.content\n",
        "print(\"\\n--- OpenAI Meeting Summary ---\")\n",
        "display(Markdown(meeting_summary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "Jp0Rtc9GH0EJ",
        "outputId": "b1c0186b-4fd7-4457-e5fd-72754607b69a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- OpenAI Meeting Summary ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Minutes of RCLI Project Demo Meeting\n\n**Date:** [Insert Date]  \n**Location:** [Insert Location]  \n**Attendees:** [Insert Attendees]\n\n## Summary\nThe meeting focused on discussing issues related to card management, specifically the loss of a card and the need for security measures to prevent fraudulent transactions.\n\n## Discussion Points\n- A participant reported a lost card and requested the ability to lock it to prevent unauthorized transactions.\n- The importance of card security and immediate response to loss was emphasized.\n\n## Takeaways\n- The necessity for a system feature that allows users to lock their cards instantly in the event of loss.\n\n## Action Items\n- **[Owner Name]**: Investigate and implement a feature for users to lock their cards immediately.\n- **[Owner Name]**: Create a communication plan to inform users about the process of reporting lost cards and locking them."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")"
      ],
      "metadata": {
        "id": "UcRKUgcxMew6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(LLAMA)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
        "streamer = TextStreamer(tokenizer)\n",
        "model = AutoModelForCausalLM.from_pretrained(LLAMA, device_map=\"auto\", quantization_config=quant_config)\n",
        "outputs = model.generate(inputs, max_new_tokens=2000, streamer=streamer)"
      ],
      "metadata": {
        "id": "6CujZRAgMimy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = tokenizer.decode(outputs[0])"
      ],
      "metadata": {
        "id": "102tdU_3Peam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response))"
      ],
      "metadata": {
        "id": "KlomN6CwMdoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student contribution\n",
        "\n",
        "Student Emad S. has made this powerful variation that uses `TextIteratorStreamer` to stream back results into a Gradio UI, and takes advantage of background threads for performance! I'm sharing it here if you'd like to take a look at some very interesting work. Thank you, Emad!\n",
        "\n",
        "https://colab.research.google.com/drive/1Ja5zyniyJo5y8s1LKeCTSkB2xyDPOt6D"
      ],
      "metadata": {
        "id": "kuxYecT2QDQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HdQnWEzW3lzP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}