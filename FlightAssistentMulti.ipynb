{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNsOxtb1+s872MdXtSsBA43",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajeevku1/AIAgentSamples/blob/main/FlightAssistentMulti.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a8nOd7dyNOVS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import gradio as gr\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import json\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
        "\n",
        "# Initialize OpenAI clients\n",
        "if openai_api_key:\n",
        "    openai_client = OpenAI(api_key=openai_api_key)\n",
        "else:\n",
        "    openai_client = None\n"
      ],
      "metadata": {
        "id": "MMwM-5jNO4_G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"\n",
        "You are a helpful assistant for an Airline called FlightAI.\n",
        "Give short, courteous answers, no more than 1 sentence.\n",
        "Always be accurate. If you don't know the answer, say so.\n",
        "\"\"\"\n",
        "MODEL = \"gpt-4.1-mini\""
      ],
      "metadata": {
        "id": "5McXtlpUo1N5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's start by making a useful function\n",
        "\n",
        "ticket_prices = {\"dallas to london\": \"$799\", \"dallas to paris\": \"$899\", \"dallas to tokyo\": \"$1400\", \"dallas to berlin\": \"$499\"}\n",
        "\n",
        "def get_ticket_price(destination_city):\n",
        "    print(f\"Tool called for travel leg {destination_city}\")\n",
        "    price = ticket_prices.get(destination_city.lower(), \"Unknown ticket price\")\n",
        "    return f\"The price of a ticket to {destination_city} is {price}\"\n"
      ],
      "metadata": {
        "id": "tScre3eAaEK0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There's a particular dictionary structure that's required to describe our function:\n",
        "\n",
        "price_function = {\n",
        "    \"name\": \"get_ticket_price\",\n",
        "    \"description\": \"Get the price of a return ticket to the destination city.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "                \"start_city\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The city the customer is departing from\"\n",
        "                },\n",
        "                \"destination_city\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The city that the customer wants to travel to\"\n",
        "                },\n",
        "                \"passenger_name\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The customer name who wants to travel\"\n",
        "                },\n",
        "        },\n",
        "            \"required\": [\"start_city\", \"destination_city\",\"passenger_name\"],\n",
        "            \"additionalProperties\": True\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "VgoO6vv9aJ1g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And this is included in a list of tools:\n",
        "tools = [{\"type\": \"function\", \"function\": price_function}]"
      ],
      "metadata": {
        "id": "iXEdM_Y0aSfa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(message, history):\n",
        "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = openai_client.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
        "    print(response)\n",
        "    if response.choices[0].finish_reason==\"tool_calls\":\n",
        "        message = response.choices[0].message\n",
        "        print(message)\n",
        "        response = handle_tool_call(message)\n",
        "        messages.append(message)\n",
        "        messages.append(response)\n",
        "        response = openai_client.chat.completions.create(model=MODEL, messages=messages)\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "M7a97YQ0adSj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We have to write that function handle_tool_call:\n",
        "\n",
        "def handle_tool_call(message):\n",
        "    tool_call = message.tool_calls[0]\n",
        "    if tool_call.function.name == \"get_ticket_price\":\n",
        "        print(tool_call.function.arguments)\n",
        "        arguments = json.loads(tool_call.function.arguments)\n",
        "        startcity = arguments.get('start_city')\n",
        "        destcity = arguments.get('destination_city')\n",
        "        passengerName  = arguments.get('passenger_name')\n",
        "        if not startcity or not destcity:\n",
        "            return \"none\"\n",
        "        print(f\"Tool called for {passengerName} travel leg {startcity} to {destcity}\")\n",
        "        travelLeg = startcity + \" to \" + destcity\n",
        "        price_details = get_ticket_price(travelLeg)\n",
        "        response = {\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": price_details,\n",
        "            \"tool_call_id\": tool_call.id\n",
        "        }\n",
        "    return response"
      ],
      "metadata": {
        "id": "tj4edWq8aktG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(fn=chat, type=\"messages\").launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "pIK98On9aq4x",
        "outputId": "cd15ff98-d950-4d3a-99c8-c8784183fafe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://3c2221c32989ff2b11.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3c2221c32989ff2b11.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tavily_search(query):\n",
        "    url = \"https://api.tavily.com/search\"\n",
        "    payload = {\n",
        "        \"api_key\": TAVILY_API_KEY,\n",
        "        \"query\": query,\n",
        "        \"max_results\": 3\n",
        "    }\n",
        "    return requests.post(url, json=payload).json()\n",
        "\n"
      ],
      "metadata": {
        "id": "wMKJ4nqGZC5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_with_internet(question):\n",
        "    # Step 1: Search\n",
        "    results = tavily_search(question)\n",
        "\n",
        "    # Step 2: Extract text\n",
        "    context = \"\\n\".join([r[\"content\"] for r in results[\"results\"]])\n",
        "\n",
        "    # Step 3: Ask LLM with context\n",
        "    prompt = f\"\"\"\n",
        "    Use the following web search results to answer the question.\n",
        "\n",
        "    Search Results:\n",
        "    {context}\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    Answer using the search results.\n",
        "    \"\"\"\n",
        "    #print(prompt)\n",
        "    return prompt\n"
      ],
      "metadata": {
        "id": "31O1hdV3ionY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}