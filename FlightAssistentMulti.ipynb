{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNsOxtb1+s872MdXtSsBA43",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajeevku1/AIAgentSamples/blob/main/FlightAssistentMulti.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a8nOd7dyNOVS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import gradio as gr\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import json\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
        "\n",
        "# Initialize OpenAI clients\n",
        "if openai_api_key:\n",
        "    openai_client = OpenAI(api_key=openai_api_key)\n",
        "else:\n",
        "    openai_client = None\n"
      ],
      "metadata": {
        "id": "MMwM-5jNO4_G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"\n",
        "You are a helpful assistant for an Airline called FlightAI.\n",
        "Give short, courteous answers, no more than 1 sentence.\n",
        "Always be accurate. If you don't know the answer, say so.\n",
        "\"\"\"\n",
        "MODEL = \"gpt-4.1-mini\""
      ],
      "metadata": {
        "id": "5McXtlpUo1N5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's start by making a useful function\n",
        "\n",
        "ticket_prices = {\"dallas to london\": \"$799\", \"dallas to paris\": \"$899\", \"dallas to tokyo\": \"$1400\", \"dallas to berlin\": \"$499\"}\n",
        "\n",
        "def get_ticket_price(destination_city):\n",
        "    print(f\"Tool called for travel leg {destination_city}\")\n",
        "    price = ticket_prices.get(destination_city.lower(), \"Unknown ticket price\")\n",
        "    return f\"The price of a ticket to {destination_city} is {price}\"\n"
      ],
      "metadata": {
        "id": "tScre3eAaEK0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There's a particular dictionary structure that's required to describe our function:\n",
        "\n",
        "price_function = {\n",
        "    \"name\": \"get_ticket_price\",\n",
        "    \"description\": \"Get the price of a return ticket to the destination city.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "                \"start_city\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The city the customer is departing from\"\n",
        "                },\n",
        "                \"destination_city\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The city that the customer wants to travel to\"\n",
        "                },\n",
        "                \"passenger_name\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The customer name who wants to travel\"\n",
        "                },\n",
        "        },\n",
        "            \"required\": [\"start_city\", \"destination_city\",\"passenger_name\"],\n",
        "            \"additionalProperties\": True\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "VgoO6vv9aJ1g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And this is included in a list of tools:\n",
        "tools = [{\"type\": \"function\", \"function\": price_function}]"
      ],
      "metadata": {
        "id": "iXEdM_Y0aSfa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(message, history):\n",
        "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = openai_client.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
        "    print(response)\n",
        "    if response.choices[0].finish_reason==\"tool_calls\":\n",
        "        message = response.choices[0].message\n",
        "        print(message)\n",
        "        response = handle_tool_call(message)\n",
        "        messages.append(message)\n",
        "        messages.append(response)\n",
        "        response = openai_client.chat.completions.create(model=MODEL, messages=messages)\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "M7a97YQ0adSj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We have to write that function handle_tool_call:\n",
        "\n",
        "def handle_tool_call(message):\n",
        "    tool_call = message.tool_calls[0]\n",
        "    if tool_call.function.name == \"get_ticket_price\":\n",
        "        print(tool_call.function.arguments)\n",
        "        arguments = json.loads(tool_call.function.arguments)\n",
        "        startcity = arguments.get('start_city')\n",
        "        destcity = arguments.get('destination_city')\n",
        "        passengerName  = arguments.get('passenger_name')\n",
        "        if not startcity or not destcity:\n",
        "            return \"none\"\n",
        "        print(f\"Tool called for {passengerName} travel leg {startcity} to {destcity}\")\n",
        "        travelLeg = startcity + \" to \" + destcity\n",
        "        price_details = get_ticket_price(travelLeg)\n",
        "        response = {\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": price_details,\n",
        "            \"tool_call_id\": tool_call.id\n",
        "        }\n",
        "    return response"
      ],
      "metadata": {
        "id": "tj4edWq8aktG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(fn=chat, type=\"messages\").launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pIK98On9aq4x",
        "outputId": "fb02d52a-2a62-4fe7-d137-b6d0f575f7f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://6908a266c54e25eeda.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6908a266c54e25eeda.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-D0IXQXKhWZnLV3HWqPcBa2VjhdQIz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you with your flight today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1768963632, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_376a7ccef1', usage=CompletionUsage(completion_tokens=13, prompt_tokens=136, total_tokens=149, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "ChatCompletion(id='chatcmpl-D0IXjDiUFaSpoj0KQpGDkxIySMH40', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='May I have your name, please?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1768963651, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_376a7ccef1', usage=CompletionUsage(completion_tokens=9, prompt_tokens=176, total_tokens=185, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "ChatCompletion(id='chatcmpl-D0IXs3321VrbAyxzHGIucVjXC74YX', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_L13W9mSiImA9sJCeI5sYDK6T', function=Function(arguments='{\"start_city\":\"Dallas\",\"destination_city\":\"Tokyo\",\"passenger_name\":\"Rajeev Kumar\",\"departure_date\":\"2024-06-10\"}', name='get_ticket_price'), type='function')]))], created=1768963660, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_376a7ccef1', usage=CompletionUsage(completion_tokens=40, prompt_tokens=196, total_tokens=236, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_L13W9mSiImA9sJCeI5sYDK6T', function=Function(arguments='{\"start_city\":\"Dallas\",\"destination_city\":\"Tokyo\",\"passenger_name\":\"Rajeev Kumar\",\"departure_date\":\"2024-06-10\"}', name='get_ticket_price'), type='function')])\n",
            "{\"start_city\":\"Dallas\",\"destination_city\":\"Tokyo\",\"passenger_name\":\"Rajeev Kumar\",\"departure_date\":\"2024-06-10\"}\n",
            "Tool called for Rajeev Kumar travel leg Dallas to Tokyo\n",
            "Tool called for travel leg Dallas to Tokyo\n",
            "ChatCompletion(id='chatcmpl-D0IZ3PsYxohtAQTVYIeYeBjNXZj6p', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_dRJMXtPZjL4z3jL4uqjQDeUr', function=Function(arguments='{\"start_city\":\"Dallas\",\"destination_city\":\"Berlin\",\"passenger_name\":\"Rajeev Kumar\"}', name='get_ticket_price'), type='function')]))], created=1768963733, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_376a7ccef1', usage=CompletionUsage(completion_tokens=30, prompt_tokens=238, total_tokens=268, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_dRJMXtPZjL4z3jL4uqjQDeUr', function=Function(arguments='{\"start_city\":\"Dallas\",\"destination_city\":\"Berlin\",\"passenger_name\":\"Rajeev Kumar\"}', name='get_ticket_price'), type='function')])\n",
            "{\"start_city\":\"Dallas\",\"destination_city\":\"Berlin\",\"passenger_name\":\"Rajeev Kumar\"}\n",
            "Tool called for Rajeev Kumar travel leg Dallas to Berlin\n",
            "Tool called for travel leg Dallas to Berlin\n",
            "ChatCompletion(id='chatcmpl-D0IZtRqdLMDpJiuxxDJjjnqfx4csm', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_MKuDNVDmjLth7LmgJ2FG2b7p', function=Function(arguments='{\"start_city\": \"Dallas\", \"destination_city\": \"Berlin\", \"passenger_name\": \"Rajeev Kumar\"}', name='get_ticket_price'), type='function'), ChatCompletionMessageFunctionToolCall(id='call_WyPkvfCRIEc6bb1R2M5wjliH', function=Function(arguments='{\"start_city\": \"New York City\", \"destination_city\": \"Berlin\", \"passenger_name\": \"Rajeev Kumar\"}', name='get_ticket_price'), type='function')]))], created=1768963785, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_376a7ccef1', usage=CompletionUsage(completion_tokens=78, prompt_tokens=283, total_tokens=361, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_MKuDNVDmjLth7LmgJ2FG2b7p', function=Function(arguments='{\"start_city\": \"Dallas\", \"destination_city\": \"Berlin\", \"passenger_name\": \"Rajeev Kumar\"}', name='get_ticket_price'), type='function'), ChatCompletionMessageFunctionToolCall(id='call_WyPkvfCRIEc6bb1R2M5wjliH', function=Function(arguments='{\"start_city\": \"New York City\", \"destination_city\": \"Berlin\", \"passenger_name\": \"Rajeev Kumar\"}', name='get_ticket_price'), type='function')])\n",
            "{\"start_city\": \"Dallas\", \"destination_city\": \"Berlin\", \"passenger_name\": \"Rajeev Kumar\"}\n",
            "Tool called for Rajeev Kumar travel leg Dallas to Berlin\n",
            "Tool called for travel leg Dallas to Berlin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/queueing.py\", line 759, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 354, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2191, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1696, in call_function\n",
            "    prediction = await fn(*processed_input)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/utils.py\", line 882, in async_wrapper\n",
            "    response = await f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py\", line 553, in __wrapper\n",
            "    return await submit_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py\", line 943, in _submit_fn\n",
            "    response = await anyio.to_thread.run_sync(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/to_thread.py\", line 63, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 2502, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 986, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-4047090337.py\", line 12, in chat\n",
            "    response = openai_client.chat.completions.create(model=MODEL, messages=messages)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 1192, in create\n",
            "    return self._post(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1259, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1047, in request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.BadRequestError: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_WyPkvfCRIEc6bb1R2M5wjliH\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://6908a266c54e25eeda.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tavily_search(query):\n",
        "    url = \"https://api.tavily.com/search\"\n",
        "    payload = {\n",
        "        \"api_key\": TAVILY_API_KEY,\n",
        "        \"query\": query,\n",
        "        \"max_results\": 3\n",
        "    }\n",
        "    return requests.post(url, json=payload).json()\n",
        "\n"
      ],
      "metadata": {
        "id": "wMKJ4nqGZC5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_with_internet(question):\n",
        "    # Step 1: Search\n",
        "    results = tavily_search(question)\n",
        "\n",
        "    # Step 2: Extract text\n",
        "    context = \"\\n\".join([r[\"content\"] for r in results[\"results\"]])\n",
        "\n",
        "    # Step 3: Ask LLM with context\n",
        "    prompt = f\"\"\"\n",
        "    Use the following web search results to answer the question.\n",
        "\n",
        "    Search Results:\n",
        "    {context}\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    Answer using the search results.\n",
        "    \"\"\"\n",
        "    #print(prompt)\n",
        "    return prompt\n"
      ],
      "metadata": {
        "id": "31O1hdV3ionY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}